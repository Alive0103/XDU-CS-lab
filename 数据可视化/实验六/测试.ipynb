{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\数据可视化\\\\实验六\\\\analysis_output.html'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.charts import Scatter, Bar, Grid\n",
    "from pyecharts import options as opts\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "file_path = './数据/合并后的数据.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "\n",
    "# Step 1: 计算每个知识点的平均得分和答题量\n",
    "knowledge_score_data = data.groupby('knowledge').agg(\n",
    "    avg_score=('score_x', 'mean'),\n",
    "    count=('score_x', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# 将数据列强制转换为列表格式\n",
    "knowledge_list = knowledge_score_data['knowledge'].tolist()\n",
    "avg_score_list = knowledge_score_data['avg_score'].tolist()\n",
    "count_list = knowledge_score_data['count'].tolist()\n",
    "\n",
    "# Step 2: 创建散点图展示知识掌握水平与平均得分的关系\n",
    "scatter = (\n",
    "    Scatter()\n",
    "    .add_xaxis(knowledge_list)\n",
    "    .add_yaxis(\n",
    "        \"Average Score\",\n",
    "        avg_score_list,\n",
    "        symbol_size=[min(50, max(10, c / 2)) for c in count_list],  # 控制气泡大小\n",
    "        itemstyle_opts=opts.ItemStyleOpts(opacity=0.7)  # 设置透明度\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"知识掌握水平与平均得分的关系\"),\n",
    "        xaxis_opts=opts.AxisOpts(name=\"知识掌握水平\", axislabel_opts={\"rotate\": 45}),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"平均得分\", min_=0),\n",
    "        tooltip_opts=opts.TooltipOpts(trigger=\"axis\", axis_pointer_type=\"cross\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 3: 创建直方图展示不同得分分布情况\n",
    "score_distribution = data['score_x'].value_counts().sort_index()\n",
    "score_x = score_distribution.index.tolist()\n",
    "score_y = score_distribution.values.tolist()\n",
    "\n",
    "bar = (\n",
    "    Bar()\n",
    "    .add_xaxis(score_x)\n",
    "    .add_yaxis(\"答题次数\", score_y)\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"各得分的答题次数分布\"),\n",
    "        xaxis_opts=opts.AxisOpts(name=\"得分\"),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"次数\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 4: 使用 Grid 组合展示\n",
    "grid = (\n",
    "    Grid(init_opts=opts.InitOpts(width=\"1200px\", height=\"800px\"))\n",
    "    .add(scatter, grid_opts=opts.GridOpts(pos_bottom=\"60%\", pos_left=\"10%\"))\n",
    "    .add(bar, grid_opts=opts.GridOpts(pos_top=\"60%\", pos_left=\"10%\"))\n",
    ")\n",
    "\n",
    "# 保存成 HTML 文件\n",
    "grid.render(\"analysis_output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\数据可视化\\\\实验六\\\\per_question_tab.html'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.charts import Bar, Page, Tab\n",
    "from pyecharts import options as opts\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "file_path = './数据/合并后的数据.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "\n",
    "# 获取所有题目 ID 列表\n",
    "titles = data['title_ID'].unique()\n",
    "\n",
    "# 创建一个 Tab 容器\n",
    "tab = Tab()\n",
    "\n",
    "# 遍历每个题目 ID，生成其得分分布直方图，并将其加入 Tab 中\n",
    "for title in titles:\n",
    "    # 筛选出当前题目的数据\n",
    "    title_data = data[data['title_ID'] == title]\n",
    "    \n",
    "    # 统计当前题目的得分分布\n",
    "    score_distribution = title_data['score_x'].value_counts().sort_index()\n",
    "    score_x = score_distribution.index.tolist()\n",
    "    score_y = score_distribution.values.tolist()\n",
    "    \n",
    "    # 创建直方图\n",
    "    bar = (\n",
    "        Bar()\n",
    "        .add_xaxis(score_x)\n",
    "        .add_yaxis(\"答题次数\", score_y)\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=f\"题目 {title} 的得分分布\"),\n",
    "            xaxis_opts=opts.AxisOpts(name=\"得分\"),\n",
    "            yaxis_opts=opts.AxisOpts(name=\"次数\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 将每个题目的图表添加到 Tab 容器中，并以题目 ID 作为 Tab 名称\n",
    "    tab.add(bar, f\"题目 {title}\")\n",
    "\n",
    "# 保存成 HTML 文件，包含所有题目的得分分布图表\n",
    "tab.render(\"per_question_tab.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\数据可视化\\\\实验六\\\\learn.html'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "from pyecharts.charts import Bar, Line, Pie, Scatter, Page\n",
    "from pyecharts import options as opts\n",
    "\n",
    "# 加载数据\n",
    "file_path = './数据/合并后的数据.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 timeconsume 列为数值，无法转换的设置为 NaN\n",
    "data['timeconsume'] = pd.to_numeric(data['timeconsume'], errors='coerce')\n",
    "\n",
    "# 1. 编程语言使用偏好分析\n",
    "language_distribution = data['method'].value_counts().reset_index()\n",
    "language_distribution.columns = ['编程语言', '答题次数']\n",
    "\n",
    "pie_language = (\n",
    "    Pie()\n",
    "    .add(\n",
    "        \"编程语言\",\n",
    "        [list(z) for z in zip(language_distribution['编程语言'], language_distribution['答题次数'])]\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"编程语言使用偏好\"),\n",
    "        legend_opts=opts.LegendOpts(orient=\"vertical\", pos_top=\"15%\", pos_left=\"2%\")\n",
    "    )\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}次\"))\n",
    ")\n",
    "\n",
    "# 2. 编程语言与平均得分分析\n",
    "language_score = data.groupby('method')['score_x'].mean().reset_index()\n",
    "language_score.columns = ['编程语言', '平均得分']\n",
    "\n",
    "bar_language_score = (\n",
    "    Bar()\n",
    "    .add_xaxis(language_score['编程语言'].tolist())\n",
    "    .add_yaxis(\"平均得分\", language_score['平均得分'].tolist())\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"编程语言与平均得分\"),\n",
    "        xaxis_opts=opts.AxisOpts(name=\"编程语言\"),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"平均得分\", min_=0, max_=4)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. 编程语言与答题耗时分析\n",
    "# 过滤掉 NaN 值\n",
    "language_timeconsume = data.dropna(subset=['timeconsume']).groupby('method')['timeconsume'].mean().reset_index()\n",
    "language_timeconsume.columns = ['编程语言', '平均答题耗时']\n",
    "\n",
    "line_language_timeconsume = (\n",
    "    Line()\n",
    "    .add_xaxis(language_timeconsume['编程语言'].tolist())\n",
    "    .add_yaxis(\"平均耗时 (秒)\", language_timeconsume['平均答题耗时'].tolist(), label_opts=opts.LabelOpts(formatter=\"{c} s\"))\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"编程语言与答题耗时\"),\n",
    "        xaxis_opts=opts.AxisOpts(name=\"编程语言\"),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"平均耗时 (秒)\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 生成HTML看板\n",
    "page = Page(layout=Page.DraggablePageLayout)\n",
    "page.add(pie_language, bar_language_score, line_language_timeconsume)\n",
    "\n",
    "# 渲染为 HTML 文件\n",
    "page.render(\"learn.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据已保存为 './数据/SubmitRecord-Class1_merged_data.xlsx' 文件。\n",
      "合并后的数据已保存为 './数据/SubmitRecord-Class2_merged_data.xlsx' 文件。\n",
      "合并后的数据已保存为 './数据/SubmitRecord-Class3_merged_data.xlsx' 文件。\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 加载题目和学生的属性数据，只需加载一次\n",
    "question_attributes = pd.read_csv('./数据/题目属性.csv')\n",
    "student_attributes = pd.read_csv('./数据/学生属性.csv')\n",
    "\n",
    "# 获取所有班级数据文件的路径\n",
    "file_paths = [\n",
    "    './数据/Data_SubmitRecord/SubmitRecord-Class1.csv',\n",
    "    './数据/Data_SubmitRecord/SubmitRecord-Class2.csv',\n",
    "    './数据/Data_SubmitRecord/SubmitRecord-Class3.csv',\n",
    "    # 添加其他班级数据文件路径\n",
    "]\n",
    "\n",
    "# 遍历每个班级的数据文件，合并并保存为 Excel 文件\n",
    "for file_path in file_paths:\n",
    "    # 读取班级提交记录数据\n",
    "    submit_records = pd.read_csv(file_path)\n",
    "    \n",
    "    # 提取班级名称（假设文件名包含班级信息）\n",
    "    class_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # 合并数据\n",
    "    merged_data = pd.merge(submit_records, question_attributes, on='title_ID', how='left')\n",
    "    merged_data = pd.merge(merged_data, student_attributes, on='student_ID', how='left')\n",
    "    \n",
    "    # 保存合并后的数据到 Excel 文件\n",
    "    output_path = f'./数据/{class_name}_merged_data.xlsx'\n",
    "    merged_data.to_excel(output_path, index=False)\n",
    "    print(f\"合并后的数据已保存为 '{output_path}' 文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc1 in position 16: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 合并和清洗每个班级的数据，并分别保存为 Excel 和 HTML 看板\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# 读取班级数据\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     class_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# 提取班级名称（假设文件名包含班级信息）\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\shumo\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\shumo\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\shumo\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\shumo\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\shumo\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc1 in position 16: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyecharts.charts import Bar, Line, Pie, Scatter, Page\n",
    "from pyecharts import options as opts\n",
    "import os\n",
    "\n",
    "# 设置数据路径，假设所有班级的 CSV 数据文件存放在 './数据/Data_SubmitRecord/' 目录下\n",
    "file_paths = [\n",
    "    './数据/SubmitRecord-Class1_merged_data.xlsx',\n",
    "    './数据/SubmitRecord-Class2_merged_data.xlsx',\n",
    "    './数据/SubmitRecord-Class3_merged_data.xlsx',\n",
    "    # 添加其他班级数据文件路径\n",
    "]\n",
    "\n",
    "# 合并和清洗每个班级的数据，并分别保存为 Excel 和 HTML 看板\n",
    "for file_path in file_paths:\n",
    "    # 读取班级数据\n",
    "    class_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 提取班级名称（假设文件名包含班级信息）\n",
    "    class_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    class_data['class_name'] = class_name  # 添加班级列\n",
    "\n",
    "    # 检查是否包含所需的列\n",
    "    required_columns = ['method', 'score_x', 'timeconsume', 'time', 'knowledge']\n",
    "    missing_columns = [col for col in required_columns if col not in class_data.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"{class_name} 缺少列: {missing_columns}\")\n",
    "        continue  # 如果缺少列，跳过该文件的处理\n",
    "\n",
    "    # 数据清洗\n",
    "    class_data['timeconsume'] = pd.to_numeric(class_data['timeconsume'], errors='coerce')\n",
    "    class_data['time'] = pd.to_datetime(class_data['time'], unit='s')\n",
    "    \n",
    "    # 保存每个班级的清洗合并数据为 Excel 文件\n",
    "    class_data.to_excel(f'./数据/{class_name}_merged_data.xlsx', index=False)\n",
    "\n",
    "    # 1. 编程语言使用偏好分析\n",
    "    language_distribution = class_data['method'].value_counts().reset_index()\n",
    "    language_distribution.columns = ['编程语言', '答题次数']\n",
    "    pie_language = (\n",
    "        Pie()\n",
    "        .add(\n",
    "            \"编程语言\",\n",
    "            [list(z) for z in zip(language_distribution['编程语言'], language_distribution['答题次数'])]\n",
    "        )\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"编程语言使用偏好\"),\n",
    "            legend_opts=opts.LegendOpts(orient=\"vertical\", pos_top=\"15%\", pos_left=\"2%\")\n",
    "        )\n",
    "        .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}次\"))\n",
    "    )\n",
    "\n",
    "    # 2. 编程语言与平均得分分析\n",
    "    language_score = class_data.groupby('method')['score_x'].mean().reset_index()\n",
    "    language_score.columns = ['编程语言', '平均得分']\n",
    "    bar_language_score = (\n",
    "        Bar()\n",
    "        .add_xaxis(language_score['编程语言'].tolist())\n",
    "        .add_yaxis(\"平均得分\", language_score['平均得分'].tolist())\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"编程语言与平均得分\"),\n",
    "            xaxis_opts=opts.AxisOpts(name=\"编程语言\"),\n",
    "            yaxis_opts=opts.AxisOpts(name=\"平均得分\", min_=0, max_=4)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 3. 编程语言与答题耗时分析\n",
    "    language_timeconsume = class_data.dropna(subset=['timeconsume']).groupby('method')['timeconsume'].mean().reset_index()\n",
    "    language_timeconsume.columns = ['编程语言', '平均答题耗时']\n",
    "    line_language_timeconsume = (\n",
    "        Line()\n",
    "        .add_xaxis(language_timeconsume['编程语言'].tolist())\n",
    "        .add_yaxis(\"平均耗时 (秒)\", language_timeconsume['平均答题耗时'].tolist(), label_opts=opts.LabelOpts(formatter=\"{c} s\"))\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"编程语言与答题耗时\"),\n",
    "            xaxis_opts=opts.AxisOpts(name=\"编程语言\"),\n",
    "            yaxis_opts=opts.AxisOpts(name=\"平均耗时 (秒)\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 4. 知识点掌握情况分析\n",
    "    knowledge_mastery = class_data.groupby('knowledge')['score_x'].mean().reset_index()\n",
    "    knowledge_mastery.columns = ['知识点', '平均得分']\n",
    "    bar_knowledge = (\n",
    "        Bar()\n",
    "        .add_xaxis(knowledge_mastery['知识点'].tolist())\n",
    "        .add_yaxis(\"平均得分\", knowledge_mastery['平均得分'].tolist())\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"知识点掌握情况\"),\n",
    "            xaxis_opts=opts.AxisOpts(name=\"知识点\"),\n",
    "            yaxis_opts=opts.AxisOpts(name=\"平均得分\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 创建每个班级的页面\n",
    "    page = Page(layout=Page.DraggablePageLayout)\n",
    "    page.add(pie_language, bar_language_score, line_language_timeconsume, bar_knowledge)\n",
    "    \n",
    "    # 渲染当前班级的页面\n",
    "    page_file_path = f\"./数据/{class_name}_dashboard.html\"\n",
    "    page.render(page_file_path)\n",
    "\n",
    "# 生成包含所有班级链接的主页面\n",
    "with open(\"all_classes_dashboard.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"<html><head><title>所有班级数据看板</title></head><body>\")\n",
    "    f.write(\"<h1>所有班级数据看板</h1><ul>\")\n",
    "    for file_path in file_paths:\n",
    "        class_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        f.write(f'<li><a href=\"./数据/{class_name}_dashboard.html\">{class_name} 的数据看板</a></li>')\n",
    "    f.write(\"</ul></body></html>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shumo",
   "language": "python",
   "name": "shumo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "nbTranslate": {
   "displayLangs": [
    "cn",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "cn",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
